{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“ Named Entity Recognition + Image Classification - Demo Notebook\n",
    "---\n",
    "## ðŸŽ¯ Goal: Verify if a text description correctly matches an image of an animal\n",
    "---\n",
    "### ðŸš€ Introduction\n",
    "This notebook demonstrates:\n",
    "- How to extract animal names from text using **NER (Named Entity Recognition)**.\n",
    "- How to classify animals in images using a **CNN model**.\n",
    "- How to compare results and determine correctness.\n",
    "- How to handle **edge cases** (e.g., multiple animals, incorrect labels).\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install the required packages\n",
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Volodia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Volodia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\hub.py:106: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All dependencies imported!\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“Œ Step 1: Install & Import Dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pipeline import verify_animal\n",
    "\n",
    "print('âœ… All dependencies imported!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Step 2: Test the Pipeline on an Example\n",
    "We will run the pipeline on a sample text and image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Text and Labels:\n",
      "[CLS]: 0\n",
      "There: 0\n",
      "is: 0\n",
      "a: 0\n",
      "cat: 0\n",
      "in: 0\n",
      "the: 0\n",
      "picture: 0\n",
      ".: 0\n",
      "[SEP]: 0\n",
      "Extracted from Text: set()\n",
      "Predicted from Image: sheep\n",
      "âœ… Verification Result: False\n"
     ]
    }
   ],
   "source": [
    "# Define example inputs\n",
    "text = \"There is a cat in the picture.\"\n",
    "image_path = r\"D:\\Projects\\Winstars_AI_DS_internship_test\\task2_ner_image_pipeline\\dataset\\val\\cow\\OIP-_01xh7qI0nvypZLkOxGyIgHaFi.jpeg\"\n",
    "\n",
    "# Run the verification pipeline\n",
    "result = verify_animal(text, image_path)\n",
    "\n",
    "# Display result\n",
    "print(f'âœ… Verification Result: {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Step 3: Test Edge Cases\n",
    "Let's see how the pipeline handles edge cases, such as:\n",
    "1. **Multiple animals** mentioned in text.\n",
    "2. **Incorrect labels** in text.\n",
    "3. **Misspelled animal names**.\n",
    "4. **No animal mentioned in text.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 1: There is a dog and a cat in the picture.\n",
      "Tokenized Text and Labels:\n",
      "[CLS]: 0\n",
      "There: 0\n",
      "is: 0\n",
      "a: 0\n",
      "dog: 0\n",
      "and: 0\n",
      "a: 0\n",
      "cat: 0\n",
      "in: 0\n",
      "the: 0\n",
      "picture: 0\n",
      ".: 0\n",
      "[SEP]: 0\n",
      "Extracted from Text: set()\n",
      "Predicted from Image: sheep\n",
      "âœ… Verification Result: False\n",
      "Test Case 2: There is a tiger in the picture.\n",
      "Tokenized Text and Labels:\n",
      "[CLS]: 0\n",
      "There: 0\n",
      "is: 0\n",
      "a: 0\n",
      "tiger: 0\n",
      "in: 0\n",
      "the: 0\n",
      "picture: 0\n",
      ".: 0\n",
      "[SEP]: 0\n",
      "Extracted from Text: set()\n",
      "Predicted from Image: sheep\n",
      "âœ… Verification Result: False\n",
      "Test Case 3: There is a cta in the picture.\n",
      "Tokenized Text and Labels:\n",
      "[CLS]: 0\n",
      "There: 0\n",
      "is: 0\n",
      "a: 0\n",
      "c: 0\n",
      "##ta: 0\n",
      "in: 0\n",
      "the: 0\n",
      "picture: 0\n",
      ".: 0\n",
      "[SEP]: 0\n",
      "Extracted from Text: set()\n",
      "Predicted from Image: sheep\n",
      "âœ… Verification Result: False\n",
      "Test Case 4: This is a beautiful landscape.\n",
      "Tokenized Text and Labels:\n",
      "[CLS]: 0\n",
      "This: 0\n",
      "is: 0\n",
      "a: 0\n",
      "beautiful: 0\n",
      "landscape: 0\n",
      ".: 0\n",
      "[SEP]: 0\n",
      "Extracted from Text: set()\n",
      "Predicted from Image: sheep\n",
      "âœ… Verification Result: False\n"
     ]
    }
   ],
   "source": [
    "# Define edge case inputs\n",
    "edge_cases = [\n",
    "    (\"There is a dog and a cat in the picture.\", r\"D:\\Projects\\Winstars_AI_DS_internship_test\\task2_ner_image_pipeline\\dataset\\val\\cow\\OIP-_01xh7qI0nvypZLkOxGyIgHaFi.jpeg\"),\n",
    "    (\"There is a tiger in the picture.\", r\"D:\\Projects\\Winstars_AI_DS_internship_test\\task2_ner_image_pipeline\\dataset\\val\\cow\\OIP-_01xh7qI0nvypZLkOxGyIgHaFi.jpeg\"),\n",
    "    (\"There is a cta in the picture.\", r\"D:\\Projects\\Winstars_AI_DS_internship_test\\task2_ner_image_pipeline\\dataset\\val\\cow\\OIP-_01xh7qI0nvypZLkOxGyIgHaFi.jpeg\"),\n",
    "    (\"This is a beautiful landscape.\", r\"D:\\Projects\\Winstars_AI_DS_internship_test\\task2_ner_image_pipeline\\dataset\\val\\cow\\OIP-_01xh7qI0nvypZLkOxGyIgHaFi.jpeg\")\n",
    "]\n",
    "\n",
    "# Run pipeline on edge cases\n",
    "for i, (text, image) in enumerate(edge_cases):\n",
    "    print(f'Test Case {i+1}: {text}')\n",
    "    result = verify_animal(text, image)\n",
    "    print(f'âœ… Verification Result: {result}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
